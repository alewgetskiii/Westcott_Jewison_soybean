{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c625ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e846831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIMDIV_PRCP_URL = \"https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-pcpnst-v1.0.0-20250905\"\n",
    "CLIMDIV_TEMP_URL = \"https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-tmpcst-v1.0.0-20250905\"\n",
    "\n",
    "USDA_BASE_URL = \"https://quickstats.nass.usda.gov/api/api_GET/\"\n",
    "\n",
    "DEFAULT_STATES = [\"IA\",\"IL\",\"IN\",\"OH\",\"MO\",\"MN\",\"NE\"]\n",
    "USDA_API_KEY = \"D1ABF2AD-362D-346E-A641-93A2FA6ED6D8\"\n",
    "\n",
    "MAPPING = {\n",
    "        1:\"AL\",  2:\"AZ\",  3:\"AR\",  4:\"CA\",  5:\"CO\",  6:\"CT\",  7:\"DE\",  8:\"FL\",  9:\"GA\",\n",
    "    10:\"ID\", 11:\"IL\", 12:\"IN\", 13:\"IA\", 14:\"KS\", 15:\"KY\", 16:\"LA\", 17:\"ME\", 18:\"MD\",\n",
    "    19:\"MA\", 20:\"MI\", 21:\"MN\", 22:\"MS\", 23:\"MO\", 24:\"MT\", 25:\"NE\", 26:\"NV\", 27:\"NH\",\n",
    "    28:\"NJ\", 29:\"NM\", 30:\"NY\", 31:\"NC\", 32:\"ND\", 33:\"OH\", 34:\"OK\", 35:\"OR\", 36:\"PA\",\n",
    "    37:\"RI\", 38:\"SC\", 39:\"SD\", 40:\"TN\", 41:\"TX\", 42:\"UT\", 43:\"VT\", 44:\"VA\", 45:\"WA\",\n",
    "    46:\"WV\", 47:\"WI\", 48:\"WY\", 49:\"HI\", 50:\"AK\", 110:\"US\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e66a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dirs():\n",
    "    for p in [\"data/raw\",\"data/interim\",\"data/processed\"]:\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "ensure_dirs()\n",
    "\n",
    "def month_name(m):\n",
    "    return [\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"][m]\n",
    "\n",
    "\n",
    "def add_shortfall(df):\n",
    "    # df: colonnes ['state','year','prec_jun', ...]\n",
    "    stats = (df.groupby('state')['prec_jun']\n",
    "               .agg(mean_jun='mean', p10=lambda x: np.percentile(x, 10))\n",
    "               .reset_index())\n",
    "    df = df.merge(stats, on='state', how='left')\n",
    "    # shortfall = (mean - actual) si actual est dans le bottom 10%, sinon 0\n",
    "    df['jun_shortfall'] = np.where(\n",
    "        df['prec_jun'] <= df['p10'],\n",
    "        df['mean_jun'] - df['prec_jun'],\n",
    "        0.0\n",
    "    )\n",
    "    return df.drop(columns=['mean_jun','p10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b663763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather(url):\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    rows = []\n",
    "\n",
    "    for line in resp.text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            print(\"pas de ligne\")\n",
    "            continue\n",
    "\n",
    "        state_code = int(line[0:3])\n",
    "        division = int(line[3:4])\n",
    "        year = int(line[6:10])\n",
    "\n",
    "        if state_code > 50 and state_code != 110:\n",
    "            continue\n",
    "        \n",
    "        parts = line[8:].split()\n",
    "        if len(parts) < 12:\n",
    "            print(\"moins de 12 cols\")\n",
    "            continue  \n",
    "        values = [float(x) for x in parts[:12]]\n",
    "        \n",
    "        rows.append([state_code, division, year] + values)\n",
    "\n",
    "    cols = [\"state_code\", \"division\", \"year\"] + [f\"m{m:02d}\" for m in range(1, 13)]\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "def climdiv_statewide_month(df):\n",
    "    grp = df.groupby([\"state_code\",\"year\"]).mean(numeric_only=True).reset_index()\n",
    "    long = grp.melt(id_vars=[\"state_code\",\"year\"], value_vars=[f\"m{m:02d}\" for m in range(1,13)],\n",
    "                    var_name=\"month\", value_name=\"value\")\n",
    "    long[\"month\"] = long[\"month\"].str[1:].astype(int)\n",
    "    print(\"ok climdiv srtatewide mothn\")\n",
    "    long[\"state\"] = long[\"state_code\"].map(MAPPING)\n",
    "    return long\n",
    "\n",
    "\n",
    "\n",
    "def build_weather_table(start, end, states):\n",
    "    tdf = load_weather(CLIMDIV_TEMP_URL)\n",
    "    tdf.to_csv(\"data/raw/tdf.csv\", index=False)\n",
    "    pdf = load_weather(CLIMDIV_PRCP_URL)\n",
    "    pdf.to_csv(\"data/raw/pdf.csv\", index=False)\n",
    "\n",
    "    t_long = climdiv_statewide_month(tdf)\n",
    "    p_long = climdiv_statewide_month(pdf)\n",
    "\n",
    "    t_long = t_long.dropna(subset=[\"state\"])\n",
    "    p_long = p_long.dropna(subset=[\"state\"])\n",
    "    \n",
    "    t_long = t_long[(t_long[\"year\"].between(start, end)) & (t_long[\"state\"].isin(states))]\n",
    "    p_long = p_long[(p_long[\"year\"].between(start, end)) & (p_long[\"state\"].isin(states))]\n",
    "\n",
    "    \n",
    "    T = t_long.pivot_table(index=[\"state\",\"year\"], columns=\"month\", values=\"value\").reset_index()\n",
    "    P = p_long.pivot_table(index=[\"state\",\"year\"], columns=\"month\", values=\"value\").reset_index()\n",
    "    \n",
    "    T.columns = [\"state\",\"year\"] + [f\"t_{month_name(m).lower()}\" for m in range(1,13)]\n",
    "    P.columns = [\"state\",\"year\"] + [f\"p_{month_name(m).lower()}\" for m in range(1,13)]\n",
    "\n",
    "    T.to_csv(\"data/interim/t_long.csv\", index=False)\n",
    "    P.to_csv(\"data/interim/p_long.csv\", index=False)\n",
    "    \n",
    "    W = pd.merge(T, P, on=[\"state\",\"year\"], how=\"inner\")\n",
    "    W['temp_JA'] = W[['t_jul','t_aug']].mean(axis=1)\n",
    "    W['prec_JA'] = W[['p_jul','p_aug']].mean(axis=1)\n",
    "    W[\"prec_jun\"] = W[\"p_jun\"]\n",
    "    W['prec_JA_sq'] = 0\n",
    "    \n",
    "    print(\"ok build weather\")\n",
    "    return W[[\"state\",\"year\",\"temp_JA\",\"prec_JA\",\"prec_JA_sq\",\"prec_jun\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d2c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACRE_TO_HA = 0.40468564224\n",
    "# 1 bu soja = 60 lb = 27.2155422 kg ; 1 acre = 0.40468564224 ha\n",
    "BUAC_TO_THA = 0.0272155422 / 0.40468564224  # ≈ 0.06725106937166737\n",
    "\n",
    "def usda_quickstats(params):\n",
    "    key = USDA_API_KEY\n",
    "    if not key:\n",
    "        raise RuntimeError(\"USDA API key not found\")\n",
    "    params = dict(params)\n",
    "    params[\"key\"] = key\n",
    "    r = requests.get(USDA_BASE_URL, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return pd.DataFrame(r.json()[\"data\"])\n",
    "\n",
    "# --- Utilitaires ---\n",
    "def _to_numeric(series):\n",
    "    return pd.to_numeric(series.astype(str).str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "\n",
    "# --- État: métriques soja (garde ton helper existant) ---\n",
    "def get_soy_state_metric(start, end, states, metric, unit, out_col, agg=\"sum\"):\n",
    "    params = {\n",
    "        \"commodity_desc\": \"SOYBEANS\",\n",
    "        \"statisticcat_desc\": metric,   # \"AREA HARVESTED\" ou \"YIELD\"\n",
    "        \"unit_desc\": unit,             # \"ACRES\" ou \"BU / ACRE\", etc.\n",
    "        \"agg_level_desc\": \"STATE\",\n",
    "        \"sector_desc\": \"CROPS\",\n",
    "        \"group_desc\": \"FIELD CROPS\",\n",
    "        \"source_desc\": \"SURVEY\",\n",
    "        \"year__GE\": start,\n",
    "        \"year__LE\": end\n",
    "    }\n",
    "    df = usda_quickstats(params)\n",
    "    df = df[df[\"state_alpha\"].isin(states)].copy()\n",
    "    df[\"Value\"] = _to_numeric(df[\"Value\"])\n",
    "\n",
    "    if agg == \"mean\":\n",
    "        out = df.groupby([\"state_alpha\", \"year\"], as_index=False)[\"Value\"].mean()\n",
    "    else:\n",
    "        out = df.groupby([\"state_alpha\", \"year\"], as_index=False)[\"Value\"].sum()\n",
    "\n",
    "    out.rename(columns={\"state_alpha\": \"state\", \"Value\": out_col}, inplace=True)\n",
    "    return out\n",
    "\n",
    "def get_soy_national_yield(start, end, unit=\"BU / ACRE\"):\n",
    "    \"\"\"Rendement national (NASS, US), en BU/ACRE + conversion t/ha.\"\"\"\n",
    "    params = {\n",
    "        \"commodity_desc\": \"SOYBEANS\",\n",
    "        \"statisticcat_desc\": \"YIELD\",\n",
    "        \"unit_desc\": unit,             # \"BU / ACRE\" (source officielle)\n",
    "        \"agg_level_desc\": \"NATIONAL\",\n",
    "        \"sector_desc\": \"CROPS\",\n",
    "        \"group_desc\": \"FIELD CROPS\",\n",
    "        \"source_desc\": \"SURVEY\",\n",
    "        \"year__GE\": start,\n",
    "        \"year__LE\": end\n",
    "    }\n",
    "    df = usda_quickstats(params).copy()\n",
    "    # QuickStats renvoie \"UNITED STATES\" côté 'state_name' pour NATIONAL\n",
    "    df[\"Value\"] = _to_numeric(df[\"Value\"])\n",
    "    out = (df.groupby(\"year\", as_index=False)[\"Value\"]\n",
    "             .mean()  # sécurité si plusieurs lignes\n",
    "             .rename(columns={\"Value\": \"yield_bu_acre\"}))\n",
    "    out[\"yield_t_ha\"] = out[\"yield_bu_acre\"] * BUAC_TO_THA\n",
    "    return out[[\"year\", \"yield_bu_acre\", \"yield_t_ha\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5736a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_state_features(start, end, states):\n",
    "    # 1) météo (ta fonction existante)\n",
    "    W = build_weather_table(start, end, states)  # suppose temp_JA, prec_JA déjà dedans\n",
    "\n",
    "    # 2) rendement ÉTAT (utile pour QC, pas utilisé dans l’agrégation finale)\n",
    "    Y = get_soy_state_metric(start, end, states,\n",
    "                             \"YIELD\", \"BU / ACRE\", \"yield_bu_acre\", \"mean\")\n",
    "    Y.to_csv(\"data/raw/yield_state_bu_ac.csv\", index=False)\n",
    "\n",
    "    # 3) area harvested en ACRES -> conversion en HECTARES pour pondération\n",
    "    A = get_soy_state_metric(start, end, states,\n",
    "                             \"AREA HARVESTED\", \"ACRES\", \"acres_harvested\", \"sum\")\n",
    "    A[\"harvest_ha\"] = A[\"acres_harvested\"] * ACRE_TO_HA\n",
    "    A.to_csv(\"data/raw/harvest_state_acres_ha.csv\", index=False)\n",
    "\n",
    "    # 4) merge + shortfall + variables du modèle\n",
    "    df = W.merge(Y, on=[\"state\",\"year\"], how=\"left\").merge(A, on=[\"state\",\"year\"], how=\"left\")\n",
    "\n",
    "    # IMPORTANT: assure-toi que add_shortfall construit (mean_jun - prec_jun) si bottom 10%\n",
    "    df = add_shortfall(df)\n",
    "\n",
    "    df[\"trend\"] = df[\"year\"] - 1987\n",
    "    df[\"dummy_2003\"] = (df[\"year\"] == 2003).astype(int)\n",
    "\n",
    "    # si prec_JA_sq n’existe pas encore, laisse l’agrégateur le calculer après moyenne pondérée\n",
    "    cols = [\n",
    "        \"state\",\"year\",\n",
    "        \"yield_bu_acre\",           # QC seulement (pas utilisé pour Y national)\n",
    "        \"trend\",\"jun_shortfall\",\"temp_JA\",\"prec_JA\",\n",
    "        \"dummy_2003\",\n",
    "        \"acres_harvested\",\"harvest_ha\"\n",
    "    ]\n",
    "\n",
    "    print(\"ok build state feature\")\n",
    "    return df[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337b11f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok climdiv srtatewide mothn\n",
      "ok climdiv srtatewide mothn\n",
      "ok build weather\n",
      "ok build state feature\n",
      "    year  yield_bu_acre  yield_t_ha  trend  jun_shortfall    temp_JA  \\\n",
      "32  2020          51.76    3.480915     33       0.000000  74.056834   \n",
      "33  2021          51.00    3.429805     34       0.250905  73.363571   \n",
      "34  2022          50.40    3.389454     35       0.000000  73.249047   \n",
      "35  2023          50.22    3.377349     36       0.241538  71.791787   \n",
      "36  2024          52.38    3.522611     37       0.000000  72.467190   \n",
      "\n",
      "     prec_JA  prec_JA_sq  dummy_2003  harvest_total_acres  harvest_total_ha  \n",
      "32  4.120770   16.980746           0          289280000.0      1.170675e+08  \n",
      "33  4.073506   16.593451           0          299350000.0      1.211426e+08  \n",
      "34  3.512567   12.338130           0          304870000.0      1.233765e+08  \n",
      "35  3.269765   10.691366           0          290320000.0      1.174883e+08  \n",
      "36  4.537819   20.591799           0          299120000.0      1.210496e+08  \n"
     ]
    }
   ],
   "source": [
    "def aggregate_national(df_state, df_us_yield, method=\"weighted\", weight_col=\"harvest_ha\"):\n",
    "    rows = []\n",
    "    for year, grp in df_state.groupby(\"year\"):\n",
    "        if (method == \"weighted\") and (weight_col in grp.columns):\n",
    "            w = grp[weight_col].astype(float)\n",
    "        else:\n",
    "            w = pd.Series(1.0, index=grp.index)\n",
    "\n",
    "        # moyenne pondérée utilitaire\n",
    "        def wavg(s): return np.average(s.astype(float), weights=w)\n",
    "\n",
    "        p_ja = wavg(grp[\"prec_JA\"])\n",
    "        rows.append({\n",
    "            \"year\": int(year),\n",
    "            \"trend\": int(year - 1987),\n",
    "            \"jun_shortfall\": wavg(grp[\"jun_shortfall\"]),\n",
    "            \"temp_JA\": wavg(grp[\"temp_JA\"]),\n",
    "            \"prec_JA\": p_ja,\n",
    "            \"prec_JA_sq\": p_ja ** 2,             # carré de l’agrégat, pas moyenne des carrés\n",
    "            \"dummy_2003\": int(year == 2003),\n",
    "            \"harvest_total_ha\": float(w.sum()),\n",
    "            \"harvest_total_acres\": float(grp[\"acres_harvested\"].sum())\n",
    "        })\n",
    "\n",
    "    X = pd.DataFrame(rows).sort_values(\"year\")\n",
    "\n",
    "    # joindre le rendement NATIONAL (BU/AC + t/ha)\n",
    "    X = X.merge(df_us_yield, on=\"year\", how=\"left\")\n",
    "\n",
    "    # colonnes finales : météo pondérée + rendement national\n",
    "    order = [\"year\", \"yield_bu_acre\", \"yield_t_ha\", \"trend\",\n",
    "             \"jun_shortfall\", \"temp_JA\", \"prec_JA\", \"prec_JA_sq\",\n",
    "             \"dummy_2003\", \"harvest_total_acres\", \"harvest_total_ha\"]\n",
    "    return X[order]\n",
    "\n",
    "# --- Exécution type ---\n",
    "WAOB_STATES = [\"IA\",\"IL\",\"IN\",\"OH\",\"MO\",\"MN\",\"NE\"]  # les 7 États du modèle\n",
    "data_states = build_state_features(1988, 2024, WAOB_STATES)\n",
    "data_states.to_csv(\"data/processed/waob_features_states.csv\", index=False)\n",
    "\n",
    "us_yield = get_soy_national_yield(1988, 2024, unit=\"BU / ACRE\")\n",
    "us_yield.to_csv(\"data/raw/yield_national_bu_ac_and_t_ha.csv\", index=False)\n",
    "\n",
    "df_nat = aggregate_national(data_states, us_yield, method=\"weighted\", weight_col=\"harvest_ha\")\n",
    "df_nat.to_csv(\"data/processed/waob_features_national.csv\", index=False)\n",
    "print(df_nat.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
